def download_new_files(url='https://www.gov.uk/government/statistics/oil-and-oil-products-section-3-energy-trends'):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, "html.parser")
    
    # Create a dictionary to store the file names and URLs
    files = {}
    
    # Find all links to Excel files
    for link in soup.find_all("a"):
        if link.get("href").endswith(".xlsx"):
            file_name = link.get("href").split("/")[-1]
            if file_name not in files:
                files[file_name] = link.get("href")
    
    # Checks if File has already been downloaded and if not then appends to new_files list
    new_files = [file for file in files if not os.path.exists(file)]
    
    # Download the new files
    filenames = []

    for file_name, file_url in files.items():
        filenames.append(file_name)
        if file_name in new_files:
            response = requests.get(file_url)
            with open(file_name, "wb") as f:
                f.write(response.content)
